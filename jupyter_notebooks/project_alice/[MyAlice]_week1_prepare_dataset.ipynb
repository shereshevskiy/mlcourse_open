{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://habrastorage.org/web/677/8e1/337/6778e1337c3d4b159d7e99df94227cb2.jpg\"/>\n",
    "## Специализация \"Машинное обучение и анализ данных\"\n",
    "</center>\n",
    "<center>Автор материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Capstone проект №1. Идентификация пользователей по посещенным веб-страницам\n",
    "\n",
    "В этом проекте мы будем решать задачу идентификации пользователя по его поведению в сети Интернет. Это сложная и интересная задача на стыке анализа данных и поведенческой психологии. В качестве примера, компания Яндекс решает задачу идентификации взломщика почтового ящика по его поведению. В двух словах, взломщик будет себя вести не так, как владелец ящика: он может не удалять сообщения сразу по прочтении, как это делал хозяин, он будет по-другому ставить флажки сообщениям и даже по-своему двигать мышкой. Тогда такого злоумышленника можно идентифицировать и \"выкинуть\" из почтового ящика, предложив хозяину войти по SMS-коду. Этот пилотный проект описан в [статье](https://habrahabr.ru/company/yandex/blog/230583/) на Хабрахабре. Похожие вещи делаются, например, в Google Analytics и описываются в научных статьях, найти можно многое по фразам \"Traversal Pattern Mining\" и \"Sequential Pattern Mining\".\n",
    "\n",
    "<img src='http://i.istockimg.com/file_thumbview_approve/21546327/5/stock-illustration-21546327-identification-de-l-utilisateur.jpg'>\n",
    "\n",
    "Мы будем решать похожую задачу: по последовательности из нескольких веб-сайтов, посещенных подряд один и тем же человеком, мы будем идентифицировать этого человека. Идея такая: пользователи Интернета по-разному переходят по ссылкам, и это может помогать их идентифицировать (кто-то сначала в почту, потом про футбол почитать, затем новости, контакт, потом наконец – работать, кто-то – сразу работать).\n",
    "\n",
    "Будем использовать данные из [статьи](http://ceur-ws.org/Vol-1703/paper12.pdf) \"A Tool for Classification of Sequential Data\". И хотя мы не можем рекомендовать эту статью (описанные методы делеки от state-of-the-art, лучше обращаться к [книге](http://www.charuaggarwal.net/freqbook.pdf) \"Frequent Pattern Mining\" и последним статьям с ICDM), но данные там собраны аккуратно и представляют интерес.\n",
    "\n",
    "Имеются данные с прокси-серверов Университета Блеза Паскаля, они имеют очень простой вид. Для каждого пользователя заведен csv-файл с названием user\\*\\*\\*\\*.csv (где вместо звездочек – 4 цифры, соответствующие ID пользователя), а в нем посещения сайтов записаны в следующем формате: <br>\n",
    "\n",
    "<center>*timestamp, посещенный веб-сайт*</center>\n",
    "\n",
    "Скачать исходные данные можно по ссылке в статье, там же описание.\n",
    "Для этого задания хватит данных не по всем 3000 пользователям, а по 10 и 150. [Ссылка](https://yadi.sk/d/3gscKIdN3BCASG) на архив *capstone_user_identification* (~7 Mb, в развернутом виде ~ 60 Mb). \n",
    "\n",
    "В финальном проекте уже придется столкнуться с тем, что не все операции можно выполнить за разумное время (скажем, перебрать с кросс-валидацией 100 комбинаций параметров случайного леса на этих данных Вы вряд ли сможете), поэтому мы будем использовать параллельно 2 выборки: по 10 пользователям и по 150. Для 10 пользователей будем писать и отлаживать код, для 150 – будет рабочая версия. \n",
    "\n",
    "Данные устроены следующем образом:\n",
    "\n",
    " - В каталоге 10users лежат 10 csv-файлов с названием вида \"user[USER_ID].csv\", где [USER_ID] – ID пользователя;\n",
    " - Аналогично для каталога 150users – там 150 файлов;\n",
    " - В каталоге 3users – игрушечный пример из 3 файлов, это для отладки кода предобработки, который Вы далее напишете.\n",
    "\n",
    "На 5 неделе будет задание по [соревнованию](https://inclass.kaggle.com/c/identify-me-if-you-can4) Kaggle Inclass, которое организовано специально под Capstone проект нашей специализации. Соревнование уже открыто и, конечно, желающие могут начать уже сейчас.\n",
    "\n",
    "# <center>Неделя 1. Подготовка данных к анализу и построению моделей\n",
    "\n",
    "Первая часть проекта посвящена подготовке данных для дальнейшего описательного анализа и построения прогнозных моделей. Надо будет написать код для предобработки данных (исходно посещенные веб-сайты указаны для каждого пользователя в отдельном файле) и формирования единой обучающей выборки. Также в этой части мы познакомимся с разреженным форматом данных (матрицы `Scipy.sparse`), который хорошо подходит для данной задачи. \n",
    "\n",
    "**План 1 недели:**\n",
    " - Часть 1. Подготовка обучающей выборки\n",
    " - Часть 2. Работа с разреженным форматом данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Задание:**</font> заполните код в этой тетрадке и выберите ответы в [веб-форме](https://docs.google.com/forms/d/e/1FAIpQLSedmwHb4cOI32zKJmEP7RvgEjNoz5GbeYRc83qFXVH82KFgGA/viewform). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В этой части проекта Вам могут быть полезны видеозаписи следующих лекций 1 и 2 недели курса \"Математика и Python для анализа данных\":**\n",
    "   - [Циклы, функции, генераторы, list comprehension](https://www.coursera.org/learn/mathematics-and-python/lecture/Kd7dL/tsikly-funktsii-ghienieratory-list-comprehension)\n",
    "   - [Чтение данных из файлов](https://www.coursera.org/learn/mathematics-and-python/lecture/8Xvwp/chtieniie-dannykh-iz-failov)\n",
    "   - [Запись файлов, изменение файлов](https://www.coursera.org/learn/mathematics-and-python/lecture/vde7k/zapis-failov-izmienieniie-failov)\n",
    "   - [Pandas.DataFrame](https://www.coursera.org/learn/mathematics-and-python/lecture/rcjAW/pandas-data-frame)\n",
    "   - [Pandas. Индексация и селекция](https://www.coursera.org/learn/mathematics-and-python/lecture/lsXAR/pandas-indieksatsiia-i-sieliektsiia)\n",
    "   \n",
    "**Кроме того, в задании будут использоваться библиотеки Python [`glob`](https://docs.python.org/3/library/glob.html), [`pickle`](https://docs.python.org/2/library/pickle.html) и класс [`csr_matrix`](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.sparse.csr_matrix.html) из `Scipy.sparse`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, для лучшей воспроизводимости результатов приведем список версий основных используемых в проекте библиотек: NumPy, SciPy, Pandas, Matplotlib, Statsmodels и Scikit-learn. Для этого воспользуемся расширением [watermark](https://github.com/rasbt/watermark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.1\n",
      "IPython 5.3.0\n",
      "\n",
      "numpy 1.12.1\n",
      "scipy 0.19.0\n",
      "pandas 0.20.1\n",
      "matplotlib 2.0.2\n",
      "statsmodels 0.8.0\n",
      "sklearn 0.18.1\n",
      "\n",
      "compiler   : MSC v.1900 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 58 Stepping 9, GenuineIntel\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   : e9162b6a9d88d7228e3371ec10ce867ad0e045b1\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,statsmodels,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.1\n",
      "IPython 5.3.0\n",
      "\n",
      "numpy 1.13.1\n",
      "scipy 0.19.1\n",
      "pandas 0.20.3\n",
      "matplotlib 2.0.0\n",
      "statsmodels 0.8.0rc1\n",
      "sklearn 0.18.2\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)\n",
      "system     : Darwin\n",
      "release    : 16.7.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   : 1f49f55605dfc4979e22e6ba6a13d06b8921b8b6\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,statsmodels,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "#pip install tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на один из файлов с данными о посещенных пользователем (номер 31) веб-страницах.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Поменяйте на свой путь к данным\n",
    "#PATH_TO_DATA = '~/capstone_user_identification'\n",
    "PATH_TO_DATA = 'data/capstone_user_identification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user31_data = pd.read_csv(os.path.join(PATH_TO_DATA, \n",
    "                                       '10users/user0031.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-11-15 08:12:07</td>\n",
       "      <td>fpdownload2.macromedia.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>www.laposte.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-11-15 08:12:17</td>\n",
       "      <td>www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-11-15 08:12:18</td>\n",
       "      <td>www.laposte.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp                        site\n",
       "0  2013-11-15 08:12:07  fpdownload2.macromedia.com\n",
       "1  2013-11-15 08:12:17                 laposte.net\n",
       "2  2013-11-15 08:12:17             www.laposte.net\n",
       "3  2013-11-15 08:12:17              www.google.com\n",
       "4  2013-11-15 08:12:18             www.laposte.net"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user31_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Поставим задачу классификации: идентифицировать пользователя по сессии из 10 подряд посещенных сайтов. Объектом в этой задаче будет сессия из 10 сайтов, последовательно посещенных одним и тем же пользователем, признаками – индексы этих 10 сайтов (чуть позже здесь появится \"мешок\" сайтов, подход Bag of Words). Целевым классом будет id пользователя.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Пример для иллюстрации</center>\n",
    "**Пусть пользователя всего 2, длина сессии – 2 сайта.**\n",
    "\n",
    "<center>user0001.csv</center>\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">timestamp</th>\n",
    "    <th class=\"tg-031e\">site</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:01</td>\n",
    "    <td class=\"tg-031e\">vk.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">00:00:11</td>\n",
    "    <td class=\"tg-yw4l\">google.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:16</td>\n",
    "    <td class=\"tg-031e\">vk.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:20</td>\n",
    "    <td class=\"tg-031e\">yandex.ru</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<center>user0002.csv</center>\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">timestamp</th>\n",
    "    <th class=\"tg-031e\">site</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:02</td>\n",
    "    <td class=\"tg-031e\">yandex.ru</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">00:00:14</td>\n",
    "    <td class=\"tg-yw4l\">google.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:17</td>\n",
    "    <td class=\"tg-031e\">facebook.com</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">00:00:25</td>\n",
    "    <td class=\"tg-031e\">yandex.ru</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Идем по 1 файлу, нумеруем сайты подряд: vk.com – 1, google.com – 2 и т.д. Далее по второму файлу. \n",
    "\n",
    "Отображение сайтов в их индесы должно получиться таким:\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">site</th>\n",
    "    <th class=\"tg-yw4l\">site_id</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">vk.com</td>\n",
    "    <td class=\"tg-yw4l\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">google.com</td>\n",
    "    <td class=\"tg-yw4l\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">yandex.ru</td>\n",
    "    <td class=\"tg-yw4l\">3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">facebook.com</td>\n",
    "    <td class=\"tg-yw4l\">4</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Тогда обучающая выборка будет такой (целевой признак – user_id):\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-s6z2{text-align:center}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-hgcj{font-weight:bold;text-align:center}\n",
    ".tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-hgcj\">session_id</th>\n",
    "    <th class=\"tg-hgcj\">site1</th>\n",
    "    <th class=\"tg-hgcj\">site2</th>\n",
    "    <th class=\"tg-amwm\">user_id</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">1</td>\n",
    "    <td class=\"tg-s6z2\">1</td>\n",
    "    <td class=\"tg-s6z2\">2</td>\n",
    "    <td class=\"tg-baqh\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">2</td>\n",
    "    <td class=\"tg-s6z2\">1</td>\n",
    "    <td class=\"tg-s6z2\">3</td>\n",
    "    <td class=\"tg-baqh\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">3</td>\n",
    "    <td class=\"tg-s6z2\">3</td>\n",
    "    <td class=\"tg-s6z2\">2</td>\n",
    "    <td class=\"tg-baqh\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-s6z2\">4</td>\n",
    "    <td class=\"tg-s6z2\">4</td>\n",
    "    <td class=\"tg-s6z2\">3</td>\n",
    "    <td class=\"tg-baqh\">2</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Здесь 1 объект – это сессия из 2 посещенных сайтов 1-ым пользователем (target=1). Это сайты vk.com и google.com (номер 1 и 2). И так далее, всего 4 сессии. Пока сессии у нас не пересекаются по сайтам, то есть посещение каждого отдельного сайта относится только к одной сессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Подготовка обучающей выборки\n",
    "Реализуйте функцию *prepare_train_set*, которая принимает на вход путь к каталогу с csv-файлами *path_to_csv_files* и параметр *session_length* – длину сессии, а возвращает 2 объекта:\n",
    "- DataFrame, в котором строки соответствуют уникальным сессиям из *session_length* сайтов, *session_length* столбцов – индексам этих *session_length* сайтов и последний столбец – ID пользователя\n",
    "- частотный словарь сайтов вида {'site_string': [site_id, site_freq]}, например для недавнего игрушечного примера это будет {'vk.com': (1, 2), 'google.com': (2, 2), 'yandex.ru': (3, 3), 'facebook.com': (4, 1)}\n",
    "\n",
    "Детали:\n",
    "- Смотрите чуть ниже пример вывода, что должна возвращать функция\n",
    "- Используйте `glob` (или аналоги) для обхода файлов в каталоге. Для определенности, отсортируйте список файлов лексикографически. Удобно использовать `tqdm_notebook` (или просто `tqdm` в случае python-скрипта) для отслеживания числа выполненных итераций цикла\n",
    "- Создайте частотный словарь уникальных сайтов (вида {'site_string': (site_id, site_freq)}) и заполняйте его по ходу чтения файлов. Начните с 1\n",
    "- Рекомендуется меньшие индексы давать более часто попадающимся сайтам (приницип наименьшего описания)\n",
    "- Не делайте entity recognition, считайте *google.com*, *http://www.google.com* и *www.google.com* разными сайтами (подключить entity recognition можно уже в рамках индивидуальной работы над проектом)\n",
    "- Скорее всего в файле число записей не кратно числу *session_length*. Тогда последняя сессия будет короче. Остаток заполняйте нулями. То есть если в файле 24 записи и сессии длины 10, то 3 сессия будет состоять из 4 сайтов, и ей мы сопоставим вектор [*site1_id*, *site2_id*, *site3_id*, *site4_id*, 0, 0, 0, 0, 0, 0, *user_id*] \n",
    "- В итоге некоторые сессии могут повторяться – оставьте как есть, не удаляйте дубликаты. Если в двух сессиях все сайты одинаковы, но сессии принадлежат разным пользователям, то тоже оставляйте как есть, это естественная неопределенность в данных\n",
    "- Не оставляйте в частотном словаре сайт 0 (уже в конце, когда функция возвращает этот словарь)\n",
    "- 150 файлов из *capstone_websites_data/150users/* у меня обработались за 1.7 секунды, но многое, конечно, зависит от реализации функции и от используемого железа. И вообще, первая реализация скорее всего будет не самой эффективной, дальше можно заняться профилированием (особенно если планируете запускать этот код для 3000 пользователей). Также эффективная реализация этой функции поможет нам на следующей неделе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### первая неэффективная реализация"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def prepare_train_set(path_to_csv_files, session_length=10):\n",
    "    ''' \n",
    "    (ВАШ КОД ЗДЕСЬ) \n",
    "    Функция принимает на вход путь к каталогу с csv-файлами path_to_csv_files и параметр session_length – длину сессии, \n",
    "    а возвращает 2 объекта:\n",
    "        - DataFrame, в котором строки соответствуют уникальным сессиям из session_length сайтов, session_length столбцов – \n",
    "        индексам этих session_length сайтов и последний столбец – ID пользователя;\n",
    "        - частотный словарь сайтов вида {'site_string': [site_id, site_freq]}, например для недавнего игрушечного примера это \n",
    "        будет {'vk.com': (1, 2), 'google.com': (2, 2), 'yandex.ru': (3, 3), 'facebook.com': (4, 1)}\n",
    "    '''\n",
    "    # инициализация\n",
    "    freq_dict = {}\n",
    "    site_id = 1\n",
    "    len_frec_dict = 0\n",
    "    data_toy = pd.DataFrame(np.zeros(session_length + 1).reshape(1, session_length + 1))\n",
    "    data_toy.columns = ['site{}'.format(i) for i in range(1, session_length + 1)] + ['user_id']\n",
    "    \n",
    "    # подготовим пути для обхода и обойдем:\n",
    "    for path in tqdm_notebook(glob(os.path.join(path_to_csv_files, 'user*.csv'))):\n",
    "        \n",
    "        user_id = int(path[-8:-4])\n",
    "                                          \n",
    "        # откроем файл\n",
    "        with open(path) as inp_csv:\n",
    "\n",
    "            # прогуляемся по строкам файла\n",
    "            n = 0 # счетчик сессий внутри файла\n",
    "            for line in inp_csv:\n",
    "                pair = line.strip().split(',')\n",
    "                # пропустим заголовки\n",
    "                if pair[1] == 'site':\n",
    "                    continue\n",
    "                time, site_string = pair\n",
    "                # очистим от пробелов\n",
    "                site_string = site_string.strip()\n",
    "\n",
    "                # формируем частотный словарь\n",
    "                if site_string in freq_dict.keys():\n",
    "                    freq_dict[site_string][1] += 1\n",
    "                else:\n",
    "                    freq_dict[site_string] = [site_id, 1]\n",
    "                    site_id += 1\n",
    "\n",
    "\n",
    "                # формируем DataFrame\n",
    "                ind = len_frec_dict + n // session_length\n",
    "                data_toy.loc[ind, 'site{}'.format(n % session_length + 1)] = freq_dict[site_string][0]\n",
    "                data_toy.loc[ind, 'user_id'] = user_id\n",
    "                \n",
    "                n += 1\n",
    "    \n",
    "            len_frec_dict = data_toy.shape[0]\n",
    "             \n",
    "    return data_toy.fillna(0).applymap(int), freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### вторая немного более эффективная реализация"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def prepare_train_set(path_to_csv_files, session_length=10):\n",
    "    ''' \n",
    "    (ВАШ КОД ЗДЕСЬ) \n",
    "    Функция принимает на вход путь к каталогу с csv-файлами path_to_csv_files и параметр session_length – длину сессии, \n",
    "    а возвращает 2 объекта:\n",
    "        - DataFrame, в котором строки соответствуют уникальным сессиям из session_length сайтов, session_length столбцов – \n",
    "        индексам этих session_length сайтов и последний столбец – ID пользователя;\n",
    "        - частотный словарь сайтов вида {'site_string': [site_id, site_freq]}, например для недавнего игрушечного примера это \n",
    "        будет {'vk.com': (1, 2), 'google.com': (2, 2), 'yandex.ru': (3, 3), 'facebook.com': (4, 1)}\n",
    "    '''\n",
    "    # инициализация\n",
    "    freq_dict = {}\n",
    "    # добавим \"0\" в частотный словарь, чтобы избежать ошибок (потом его удалим)\n",
    "    freq_dict[0] = [0, 0]\n",
    "    site_dict = {}\n",
    "    site_id = 1\n",
    "    array_toy = np.zeros(session_length + 1).reshape(1, session_length + 1)\n",
    "       \n",
    "    # подготовим пути для обхода и обойдем:\n",
    "    for path in tqdm_notebook(glob(os.path.join(path_to_csv_files, 'user*.csv'))):\n",
    "        \n",
    "        # считаем файл\n",
    "        data = pd.read_csv(path, header=0, index_col=0)    \n",
    "        \n",
    "        user_id = int(path[-8:-4])\n",
    "        \n",
    "        # формируем частотный словарь\n",
    "        for site_string in data['site'].value_counts().index:\n",
    "            if site_string in freq_dict.keys():\n",
    "                freq_dict[site_string][1] += data['site'].value_counts().loc[site_string]\n",
    "            else:\n",
    "                freq_dict[site_string] = [site_id, data['site'].value_counts().loc[site_string]]\n",
    "                site_id += 1\n",
    "         \n",
    "        # формируем массив уникальных сессий через reshape(-1, session_length), \n",
    "        #                         предварительно дополнив нулями до кратности session_length                        \n",
    "\n",
    "        num_zeros = session_length - data['site'].shape[0] % session_length if data['site'].shape[0] % session_length != 0 else 0\n",
    "        \n",
    "        array_toy_loc = np.hstack((data['site'].values, np.zeros(num_zeros))).reshape((-1, session_length))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # добавим колонку с user_id\n",
    "        col_user_id = np.zeros([array_toy_loc.shape[0], 1]) + user_id # forming columns with user_id\n",
    "        array_toy_loc = np.hstack((array_toy_loc, col_user_id))\n",
    "        \n",
    "        # накапливаем сессии\n",
    "        array_toy = np.vstack((array_toy, array_toy_loc))   \n",
    "            \n",
    "    # готовим датафрейм сессий на выдачу\n",
    "    data_toy = pd.DataFrame(array_toy[1:]) # убираем 1 нулевую строку                           \n",
    "    data_toy.columns = ['site{}'.format(i) for i in range(1, session_length + 1)] + ['user_id']\n",
    "    \n",
    "    # перекодируем site_string в коды по словарю\n",
    "    data_toy.iloc[:, :-1] = data_toy.iloc[:, :-1].applymap(lambda x: freq_dict[x][0])\n",
    "       \n",
    "    freq_dict.pop(0) # удаляем лишний 0-ключ\n",
    "                                 \n",
    "    return data_toy, freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ИТОГОВАЯ эффективная реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_set(path_to_csv_files, session_length=10):\n",
    "    ''' \n",
    "    (ВАШ КОД ЗДЕСЬ) \n",
    "    Функция принимает на вход путь к каталогу с csv-файлами path_to_csv_files и параметр session_length – длину сессии, \n",
    "    а возвращает 2 объекта:\n",
    "        - DataFrame, в котором строки соответствуют уникальным сессиям из session_length сайтов, session_length столбцов – \n",
    "        индексам этих session_length сайтов и последний столбец – ID пользователя;\n",
    "        - частотный словарь сайтов вида {'site_string': [site_id, site_freq]}, например для недавнего игрушечного примера это \n",
    "        будет {'vk.com': (1, 2), 'google.com': (2, 2), 'yandex.ru': (3, 3), 'facebook.com': (4, 1)}\n",
    "    '''\n",
    "    # инициализация\n",
    "    freq_dict = {} # частотный словарь\n",
    "    # добавим \"0\" в частотный словарь, чтобы избежать ошибок (потом его удалим)\n",
    "    freq_dict[0] = [0, 0]\n",
    "    \n",
    "    site_id = 1 # счетчик для кодирования сайтов\n",
    "    # заготовка для массива уникальных сессий\n",
    "    array_toy = np.zeros(session_length + 1).reshape(1, session_length + 1)\n",
    "       \n",
    "    # подготовим пути для обхода и обойдем:\n",
    "    for path in tqdm_notebook(glob(os.path.join(path_to_csv_files, 'user*.csv'))):\n",
    "        \n",
    "        # считаем файл\n",
    "        data_readed = pd.read_csv(path, header=0, index_col=0)\n",
    "        data = data_readed['site'].values.copy() # и скопируем его в numpy-массив\n",
    "        \n",
    "        user_id = int(path[-8:-4]) # id пользователя\n",
    "        \n",
    "        # формируем частотный словарь\n",
    "        for site_string in data:\n",
    "            if site_string in freq_dict:\n",
    "                freq_dict[site_string][1] += 1\n",
    "            else:\n",
    "                freq_dict[site_string] = [site_id, 1]\n",
    "                site_id += 1\n",
    "        \n",
    "        # формируем массив уникальных сессий через resize                        \n",
    "        row = int(data.shape[0] / session_length) + 1 if data.shape[0] % session_length != 0 \\\n",
    "                                                      else int(data.shape[0] / session_length)\n",
    "        data.resize((row, session_length))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # добавим колонку с user_id\n",
    "        col_user_id = np.zeros([data.shape[0], 1]) + user_id # forming columns with user_id\n",
    "        data = np.hstack((data, col_user_id))\n",
    "        \n",
    "        # накапливаем сессии\n",
    "        array_toy = np.vstack((array_toy, data))   \n",
    "            \n",
    "    # готовим датафрейм сессий на выдачу\n",
    "    data_toy = pd.DataFrame(array_toy[1:]) # убираем 1 нулевую строку                           \n",
    "    data_toy.columns = ['site{}'.format(i) for i in range(1, session_length + 1)] + ['user_id']\n",
    "    \n",
    "    # перекодируем site_string в коды по словарю\n",
    "    data_toy.iloc[:, :-1] = data_toy.iloc[:, :-1].applymap(lambda x: freq_dict[x][0])\n",
    "       \n",
    "    freq_dict.pop(0) # удаляем лишний нулевой ключ\n",
    "                                 \n",
    "    return data_toy.applymap(int), freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примените полученную функцию к игрушечному примеру, убедитесь, что все работает как надо.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp,site\n",
      "2013-11-15 09:28:17,vk.com\n",
      "2013-11-15 09:33:04,oracle.com\n",
      "2013-11-15 09:52:48,oracle.com\n",
      "2013-11-15 11:37:26,geo.mozilla.org\n",
      "2013-11-15 11:40:32,oracle.com\n",
      "2013-11-15 11:40:34,google.com\n",
      "2013-11-15 11:40:35,accounts.google.com\n",
      "2013-11-15 11:40:37,mail.google.com\n",
      "2013-11-15 11:40:40,apis.google.com\n",
      "2013-11-15 11:41:35,plus.google.com\n",
      "2013-11-15 12:40:35,vk.com\n",
      "2013-11-15 12:40:37,google.com\n",
      "2013-11-15 12:40:40,google.com\n",
      "2013-11-15 12:41:35,google.com\n"
     ]
    }
   ],
   "source": [
    "!cat $PATH_TO_DATA/3users/user0001.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp,site\n",
      "2013-11-15 09:28:17,vk.com\n",
      "2013-11-15 09:33:04,oracle.com\n",
      "2013-11-15 09:52:48,football.kulichki.ru\n",
      "2013-11-15 11:37:26,football.kulichki.ru\n",
      "2013-11-15 11:40:32,oracle.com\n"
     ]
    }
   ],
   "source": [
    "!cat $PATH_TO_DATA/3users/user0002.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp,site\n",
      "2013-11-15 09:28:17,meduza.io\n",
      "2013-11-15 09:33:04,google.com\n",
      "2013-11-15 09:52:48,oracle.com\n",
      "2013-11-15 11:37:26,google.com\n",
      "2013-11-15 11:40:32,oracle.com\n",
      "2013-11-15 11:40:34,google.com\n",
      "2013-11-15 11:40:35,google.com\n",
      "2013-11-15 11:40:37,mail.google.com\n",
      "2013-11-15 11:40:40,yandex.ru\n",
      "2013-11-15 11:41:35,meduza.io\n",
      "2013-11-15 12:28:17,meduza.io\n",
      "2013-11-15 12:33:04,google.com\n",
      "2013-11-15 12:52:48,oracle.com\n"
     ]
    }
   ],
   "source": [
    "!cat $PATH_TO_DATA/3users/user0003.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ac4b30dc6e454c8baf568c2128dd67"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_toy, site_freq_3users = prepare_train_set(os.path.join(PATH_TO_DATA, '3users'), \n",
    "                                                     session_length=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**моя реализация**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  site1 site2 site3 site4 site5 site6 site7 site8 site9 site10 user_id\n",
       "0     1     2     2     3     2     4     5     6     7      8       1\n",
       "1     1     4     4     4     0     0     0     0     0      0       1\n",
       "2     1     2     9     9     2     0     0     0     0      0       2\n",
       "3    10     4     2     4     2     4     4     6    11     10       3\n",
       "4    10     4     2     0     0     0     0     0     0      0       3"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_toy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**АВТОРСКАЯ реализация**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site1  site2  site3  site4  site5  site6  site7  site8  site9  site10  \\\n",
       "0      3      2      2     10      2      1      7      5      8       9   \n",
       "1      3      1      1      1      0      0      0      0      0       0   \n",
       "2      3      2      6      6      2      0      0      0      0       0   \n",
       "3      4      1      2      1      2      1      1      5     11       4   \n",
       "4      4      1      2      0      0      0      0      0      0       0   \n",
       "\n",
       "   user_id  \n",
       "0        1  \n",
       "1        1  \n",
       "2        2  \n",
       "3        3  \n",
       "4        3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_toy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Частоты сайтов (второй элемент кортежа) точно должны быть такими, нумерация может быть любой (первые элементы кортежей могут отличаться)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**моя реализация**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accounts.google.com': [5, 1],\n",
       " 'apis.google.com': [7, 1],\n",
       " 'football.kulichki.ru': [9, 2],\n",
       " 'geo.mozilla.org': [3, 1],\n",
       " 'google.com': [4, 9],\n",
       " 'mail.google.com': [6, 2],\n",
       " 'meduza.io': [10, 3],\n",
       " 'oracle.com': [2, 8],\n",
       " 'plus.google.com': [8, 1],\n",
       " 'vk.com': [1, 3],\n",
       " 'yandex.ru': [11, 1]}"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_freq_3users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**АВТОРСКАЯ реализация**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accounts.google.com': (7, 1),\n",
       " 'apis.google.com': (8, 1),\n",
       " 'football.kulichki.ru': (6, 2),\n",
       " 'geo.mozilla.org': (10, 1),\n",
       " 'google.com': (1, 9),\n",
       " 'mail.google.com': (5, 2),\n",
       " 'meduza.io': (4, 3),\n",
       " 'oracle.com': (2, 8),\n",
       " 'plus.google.com': (9, 1),\n",
       " 'vk.com': (3, 3),\n",
       " 'yandex.ru': (11, 1)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_freq_3users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените полученную функцию к данным по 10 пользователям.\n",
    "\n",
    "**<font color='red'> Вопрос 1. </font> Сколько уникальных сессий из 10 сайтов в выборке с 10 пользователями?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683c0fc9846f44379ef7c882db8d9593"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "train_data_10users, site_freq_10users = prepare_train_set(os.path.join(PATH_TO_DATA, '10users'), \n",
    "                                                     session_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>14</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44</td>\n",
       "      <td>36</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>49</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>51</td>\n",
       "      <td>59</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>59</td>\n",
       "      <td>67</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>59</td>\n",
       "      <td>68</td>\n",
       "      <td>15</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>59</td>\n",
       "      <td>61</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>72</td>\n",
       "      <td>59</td>\n",
       "      <td>15</td>\n",
       "      <td>58</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>73</td>\n",
       "      <td>51</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>78</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>79</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>85</td>\n",
       "      <td>79</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>51</td>\n",
       "      <td>81</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>79</td>\n",
       "      <td>51</td>\n",
       "      <td>86</td>\n",
       "      <td>89</td>\n",
       "      <td>88</td>\n",
       "      <td>78</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>79</td>\n",
       "      <td>88</td>\n",
       "      <td>79</td>\n",
       "      <td>89</td>\n",
       "      <td>80</td>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "      <td>79</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>91</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>86</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>79</td>\n",
       "      <td>86</td>\n",
       "      <td>89</td>\n",
       "      <td>86</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>89</td>\n",
       "      <td>79</td>\n",
       "      <td>89</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "      <td>79</td>\n",
       "      <td>89</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>89</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>86</td>\n",
       "      <td>89</td>\n",
       "      <td>86</td>\n",
       "      <td>79</td>\n",
       "      <td>86</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>86</td>\n",
       "      <td>8</td>\n",
       "      <td>86</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>89</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>89</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>51</td>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>96</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>42</td>\n",
       "      <td>101</td>\n",
       "      <td>98</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14031</th>\n",
       "      <td>567</td>\n",
       "      <td>587</td>\n",
       "      <td>567</td>\n",
       "      <td>577</td>\n",
       "      <td>575</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>578</td>\n",
       "      <td>566</td>\n",
       "      <td>1494</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14032</th>\n",
       "      <td>1494</td>\n",
       "      <td>1494</td>\n",
       "      <td>575</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>9</td>\n",
       "      <td>576</td>\n",
       "      <td>575</td>\n",
       "      <td>575</td>\n",
       "      <td>576</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14033</th>\n",
       "      <td>575</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>575</td>\n",
       "      <td>580</td>\n",
       "      <td>569</td>\n",
       "      <td>568</td>\n",
       "      <td>579</td>\n",
       "      <td>568</td>\n",
       "      <td>628</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14034</th>\n",
       "      <td>629</td>\n",
       "      <td>629</td>\n",
       "      <td>567</td>\n",
       "      <td>566</td>\n",
       "      <td>758</td>\n",
       "      <td>630</td>\n",
       "      <td>576</td>\n",
       "      <td>575</td>\n",
       "      <td>629</td>\n",
       "      <td>575</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14035</th>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>575</td>\n",
       "      <td>576</td>\n",
       "      <td>575</td>\n",
       "      <td>576</td>\n",
       "      <td>568</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>569</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14036</th>\n",
       "      <td>568</td>\n",
       "      <td>51</td>\n",
       "      <td>2036</td>\n",
       "      <td>2036</td>\n",
       "      <td>2036</td>\n",
       "      <td>51</td>\n",
       "      <td>433</td>\n",
       "      <td>433</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14037</th>\n",
       "      <td>433</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>2342</td>\n",
       "      <td>4</td>\n",
       "      <td>433</td>\n",
       "      <td>434</td>\n",
       "      <td>4</td>\n",
       "      <td>2342</td>\n",
       "      <td>433</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14038</th>\n",
       "      <td>433</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>568</td>\n",
       "      <td>433</td>\n",
       "      <td>51</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>532</td>\n",
       "      <td>2342</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14039</th>\n",
       "      <td>70</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>568</td>\n",
       "      <td>4</td>\n",
       "      <td>532</td>\n",
       "      <td>594</td>\n",
       "      <td>534</td>\n",
       "      <td>532</td>\n",
       "      <td>4</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14040</th>\n",
       "      <td>532</td>\n",
       "      <td>594</td>\n",
       "      <td>319</td>\n",
       "      <td>568</td>\n",
       "      <td>532</td>\n",
       "      <td>533</td>\n",
       "      <td>532</td>\n",
       "      <td>211</td>\n",
       "      <td>532</td>\n",
       "      <td>532</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14041</th>\n",
       "      <td>604</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>1347</td>\n",
       "      <td>51</td>\n",
       "      <td>1349</td>\n",
       "      <td>1350</td>\n",
       "      <td>1348</td>\n",
       "      <td>1868</td>\n",
       "      <td>10</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14042</th>\n",
       "      <td>132</td>\n",
       "      <td>1888</td>\n",
       "      <td>1869</td>\n",
       "      <td>1868</td>\n",
       "      <td>211</td>\n",
       "      <td>565</td>\n",
       "      <td>1869</td>\n",
       "      <td>566</td>\n",
       "      <td>1870</td>\n",
       "      <td>1869</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14043</th>\n",
       "      <td>33</td>\n",
       "      <td>1872</td>\n",
       "      <td>72</td>\n",
       "      <td>823</td>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>184</td>\n",
       "      <td>535</td>\n",
       "      <td>4913</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14044</th>\n",
       "      <td>2029</td>\n",
       "      <td>2029</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>15</td>\n",
       "      <td>2029</td>\n",
       "      <td>63</td>\n",
       "      <td>2029</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14045</th>\n",
       "      <td>1947</td>\n",
       "      <td>205</td>\n",
       "      <td>578</td>\n",
       "      <td>1871</td>\n",
       "      <td>1493</td>\n",
       "      <td>1493</td>\n",
       "      <td>576</td>\n",
       "      <td>575</td>\n",
       "      <td>575</td>\n",
       "      <td>576</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14046</th>\n",
       "      <td>585</td>\n",
       "      <td>585</td>\n",
       "      <td>586</td>\n",
       "      <td>576</td>\n",
       "      <td>575</td>\n",
       "      <td>569</td>\n",
       "      <td>568</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>568</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14047</th>\n",
       "      <td>568</td>\n",
       "      <td>568</td>\n",
       "      <td>568</td>\n",
       "      <td>568</td>\n",
       "      <td>579</td>\n",
       "      <td>580</td>\n",
       "      <td>628</td>\n",
       "      <td>629</td>\n",
       "      <td>567</td>\n",
       "      <td>758</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14048</th>\n",
       "      <td>630</td>\n",
       "      <td>758</td>\n",
       "      <td>51</td>\n",
       "      <td>3585</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>52</td>\n",
       "      <td>184</td>\n",
       "      <td>4</td>\n",
       "      <td>188</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14049</th>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>575</td>\n",
       "      <td>576</td>\n",
       "      <td>615</td>\n",
       "      <td>187</td>\n",
       "      <td>52</td>\n",
       "      <td>191</td>\n",
       "      <td>183</td>\n",
       "      <td>192</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14050</th>\n",
       "      <td>187</td>\n",
       "      <td>51</td>\n",
       "      <td>575</td>\n",
       "      <td>576</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14051</th>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14052</th>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>51</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>576</td>\n",
       "      <td>575</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14053</th>\n",
       "      <td>576</td>\n",
       "      <td>575</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>576</td>\n",
       "      <td>575</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14054</th>\n",
       "      <td>576</td>\n",
       "      <td>575</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>469</td>\n",
       "      <td>469</td>\n",
       "      <td>469</td>\n",
       "      <td>469</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14055</th>\n",
       "      <td>394</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>394</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14056</th>\n",
       "      <td>4</td>\n",
       "      <td>183</td>\n",
       "      <td>52</td>\n",
       "      <td>184</td>\n",
       "      <td>51</td>\n",
       "      <td>185</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>186</td>\n",
       "      <td>3585</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14057</th>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>3585</td>\n",
       "      <td>186</td>\n",
       "      <td>188</td>\n",
       "      <td>4</td>\n",
       "      <td>183</td>\n",
       "      <td>187</td>\n",
       "      <td>183</td>\n",
       "      <td>188</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14058</th>\n",
       "      <td>189</td>\n",
       "      <td>183</td>\n",
       "      <td>187</td>\n",
       "      <td>52</td>\n",
       "      <td>184</td>\n",
       "      <td>615</td>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14059</th>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>95</td>\n",
       "      <td>615</td>\n",
       "      <td>183</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>187</td>\n",
       "      <td>183</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14060</th>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14061 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       site1  site2  site3  site4  site5  site6  site7  site8  site9  site10  \\\n",
       "0          1      2      3      4      3      3      4      3      5       3   \n",
       "1          6      7      8      9      3     10     11     12     13      14   \n",
       "2         14      4     14     14     15     16      6     17     18      14   \n",
       "3         19     20     19     14     14     14     14     21     22      23   \n",
       "4         24     14     15     25     26     27     28     29     30      29   \n",
       "5         31     30     27     27     14     14     32     33     34      35   \n",
       "6         36      2      3      4      3     10      3     11      1       3   \n",
       "7         37     38     39     11     14      4     14      4     22      23   \n",
       "8         14     17     40      5     41     42     14     43     40      15   \n",
       "9         44     36     45     36     46     47     48     48     47      49   \n",
       "10        49     33     33     50     51     51     52      4     51      53   \n",
       "11        53     54     55     56     57     57     58     59     51      59   \n",
       "12        60     61     62     63     64     60     65     66     59      67   \n",
       "13        59     68     15     69     70     71     71     59     61      10   \n",
       "14        72     10     72     59     15     58     52      4     51      51   \n",
       "15        73     51     74     75     73     75     74     73     74      76   \n",
       "16        73     74     73     76     77     77     77     77     78      79   \n",
       "17        79     78     79     80     78     81     81     80     79      78   \n",
       "18        82     82     79     78     83     79     84     85     84      79   \n",
       "19        83     85     84     84     79     78     79     78     85      79   \n",
       "20        78     78     81      4     79     78     51     81     86      87   \n",
       "21        78     79      4     88     79     51     86     89     88      78   \n",
       "22        79     88     79     89     80     78     88     79     89      90   \n",
       "23        91     78     79     86     88     88     79     86     89      86   \n",
       "24        89     79     89     92     93     89     79     89     88      86   \n",
       "25        89     78     79     86     89     86     79     86     89      89   \n",
       "26        88     86     86     86      7     86      8     86     24      32   \n",
       "27        86     86     86     89     86     16     89     94     95      50   \n",
       "28        51     51      4     52     51     96     97     96     98      99   \n",
       "29        32      5     94    100     15     98     96     42    101      98   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...     ...   \n",
       "14031    567    587    567    577    575    576    576    578    566    1494   \n",
       "14032   1494   1494    575    576    576      9    576    575    575     576   \n",
       "14033    575    576    576    575    580    569    568    579    568     628   \n",
       "14034    629    629    567    566    758    630    576    575    629     575   \n",
       "14035    576    576    575    576    575    576    568     51     50     569   \n",
       "14036    568     51   2036   2036   2036     51    433    433     10       4   \n",
       "14037    433     10     51   2342      4    433    434      4   2342     433   \n",
       "14038    433      4     15    568    433     51     63     66    532    2342   \n",
       "14039     70     64     15    568      4    532    594    534    532       4   \n",
       "14040    532    594    319    568    532    533    532    211    532     532   \n",
       "14041    604     15    100   1347     51   1349   1350   1348   1868      10   \n",
       "14042    132   1888   1869   1868    211    565   1869    566   1870    1869   \n",
       "14043     33   1872     72    823      4     51     52    184    535    4913   \n",
       "14044   2029   2029     64     66     15   2029     63   2029    283     283   \n",
       "14045   1947    205    578   1871   1493   1493    576    575    575     576   \n",
       "14046    585    585    586    576    575    569    568     51     51     568   \n",
       "14047    568    568    568    568    579    580    628    629    567     758   \n",
       "14048    630    758     51   3585    185    186     52    184      4     188   \n",
       "14049    187    189    575    576    615    187     52    191    183     192   \n",
       "14050    187     51    575    576     51     51   1300   1300   1300    1300   \n",
       "14051   1300   1300   1300   1300   1300   1300   1300   1300   1300    1300   \n",
       "14052   1300   1300     51    187    187    576    575    187    187     187   \n",
       "14053    576    575    187    187    187    187    576    575    187     187   \n",
       "14054    576    575    187    187    469    469    469    469    574     574   \n",
       "14055    394     51     50     51    394    394    394     51     51      51   \n",
       "14056      4    183     52    184     51    185      4     52    186    3585   \n",
       "14057    184    185   3585    186    188      4    183    187    183     188   \n",
       "14058    189    183    187     52    184    615    187    189    183     183   \n",
       "14059    183    183    183     95    615    183      4      4    187     183   \n",
       "14060    184    185      0      0      0      0      0      0      0       0   \n",
       "\n",
       "       user_id  \n",
       "0           31  \n",
       "1           31  \n",
       "2           31  \n",
       "3           31  \n",
       "4           31  \n",
       "5           31  \n",
       "6           31  \n",
       "7           31  \n",
       "8           31  \n",
       "9           31  \n",
       "10          31  \n",
       "11          31  \n",
       "12          31  \n",
       "13          31  \n",
       "14          31  \n",
       "15          31  \n",
       "16          31  \n",
       "17          31  \n",
       "18          31  \n",
       "19          31  \n",
       "20          31  \n",
       "21          31  \n",
       "22          31  \n",
       "23          31  \n",
       "24          31  \n",
       "25          31  \n",
       "26          31  \n",
       "27          31  \n",
       "28          31  \n",
       "29          31  \n",
       "...        ...  \n",
       "14031      241  \n",
       "14032      241  \n",
       "14033      241  \n",
       "14034      241  \n",
       "14035      241  \n",
       "14036      241  \n",
       "14037      241  \n",
       "14038      241  \n",
       "14039      241  \n",
       "14040      241  \n",
       "14041      241  \n",
       "14042      241  \n",
       "14043      241  \n",
       "14044      241  \n",
       "14045      241  \n",
       "14046      241  \n",
       "14047      241  \n",
       "14048      241  \n",
       "14049      241  \n",
       "14050      241  \n",
       "14051      241  \n",
       "14052      241  \n",
       "14053      241  \n",
       "14054      241  \n",
       "14055      241  \n",
       "14056      241  \n",
       "14057      241  \n",
       "14058      241  \n",
       "14059      241  \n",
       "14060      241  \n",
       "\n",
       "[14061 rows x 11 columns]"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_10users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Вопрос 2. </font> Сколько всего уникальных сайтов в выборке из 10 пользователей? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4913"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "max(site_freq_10users.items(), key=lambda x: x[1][0])[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примените полученную функцию к данным по 150 пользователям.\n",
    "\n",
    "**<font color='red'> Вопрос 3. </font> Сколько уникальных сессий из 10 сайтов в выборке с 150 пользователями?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1588435264d465998e16799b6e22f8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 4.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "train_data_150users, site_freq_150users = prepare_train_set(os.path.join(PATH_TO_DATA, '150users'), \n",
    "                                                     session_length=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137019"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_150users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Вопрос 4. </font> Сколько всего уникальных сайтов в выборке из 150 пользователей? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27797"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "max(site_freq_150users.items(), key=lambda x: x[1][0])[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Вопрос 5. </font> Какой из этих сайтов НЕ входит в топ-10 самых популярных сайтов среди посещенных 150 пользователями?**\n",
    "- www.google.fr\n",
    "- www.youtube.com\n",
    "- safebrowsing-cache.google.com\n",
    "- **www.linkedin.com - [+]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('www.google.fr', [1, 64785]),\n",
       " ('www.google.com', [3, 51320]),\n",
       " ('www.facebook.com', [41, 39002]),\n",
       " ('apis.google.com', [2, 29983]),\n",
       " ('s.youtube.com', [181, 29102]),\n",
       " ('clients1.google.com', [214, 25087]),\n",
       " ('mail.google.com', [28, 19072]),\n",
       " ('plus.google.com', [27, 18467]),\n",
       " ('safebrowsing-cache.google.com', [293, 17960]),\n",
       " ('www.youtube.com', [105, 16319])]"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "sorted(site_freq_150users.items(), key=lambda x: x[1][1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для дальнейшего анализа запишем полученные объекты DataFrame в csv-файлы.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_10users.to_csv(os.path.join(PATH_TO_DATA, \n",
    "                                       'train_data_10users.csv'), \n",
    "                        index_label='session_id', float_format='%d')\n",
    "train_data_150users.to_csv(os.path.join(PATH_TO_DATA, \n",
    "                                        'train_data_150users.csv'), \n",
    "                         index_label='session_id', float_format='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Работа с разреженным форматом данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если так подумать, то полученные признаки *site1*, ..., *site10* смысла не имеют как признаки в задаче классификации. А вот если воспользоваться идеей мешка слов из анализа текстов – это другое дело. Создадим новые матрицы, в которых строкам будут соответствовать сессии из 10 сайтов, а столбцам – индексы сайтов. На пересечении строки $i$ и столбца $j$ будет стоять число $n_{ij}$ – cколько раз сайт $j$ встретился в сессии номер $i$. Делать это будем с помощью разреженных матриц Scipy – [csr_matrix](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.sparse.csr_matrix.html). Прочитайте документацию, разберитесь, как использовать разреженные матрицы и создайте такие матрицы для наших данных. Сначала проверьте на игрушечном примере, затем примените для 10 и 150 пользователей. \n",
    "\n",
    "Обратите внимание, что в коротких сессиях, меньше 10 сайтов, у нас остались нули, так что первый признак (сколько раз попался 0) по смыслу отличен от остальных (сколько раз попался сайт с индексом $i$). Поэтому первый столбец разреженной матрицы надо будет удалить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_toy, y_toy = train_data_toy.iloc[:, :-1].values, train_data_toy.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  2,  3,  2,  4,  5,  6,  7,  8],\n",
       "       [ 1,  4,  4,  4,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  2,  9,  9,  2,  0,  0,  0,  0,  0],\n",
       "       [10,  4,  2,  4,  2,  4,  4,  6, 11, 10],\n",
       "       [10,  4,  2,  0,  0,  0,  0,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  2,  2, 10,  2,  1,  7,  5,  8,  9],\n",
       "       [ 3,  1,  1,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3,  2,  6,  6,  2,  0,  0,  0,  0,  0],\n",
       "       [ 4,  1,  2,  1,  2,  1,  1,  5, 11,  4],\n",
       "       [ 4,  1,  2,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       "        [0, 2, 0, 4, 0, 1, 0, 0, 0, 2, 1],\n",
       "        [0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = X_toy\n",
    "indptr = [0]\n",
    "indices = []\n",
    "data = []\n",
    "vocabulary = {}\n",
    "for d in docs:\n",
    "    for term in d:\n",
    "        index = vocabulary.setdefault(term, term)\n",
    "        indices.append(index)\n",
    "        data.append(1)\n",
    "    indptr.append(len(indices))\n",
    "csr_matrix((data, indices, indptr), dtype=int)[:, 1:].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  2,  3,  2,  4,  5,  6,  7,  8],\n",
       "       [ 1,  4,  4,  4,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  2,  9,  9,  2,  0,  0,  0,  0,  0],\n",
       "       [10,  4,  2,  4,  2,  4,  4,  6, 11, 10],\n",
       "       [10,  4,  2,  0,  0,  0,  0,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 899,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(indices).reshape(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10, 20, 30, 40, 50]"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[X_toy.shape[1] * i for i in range(X_toy.shape[0] + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_toy.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "X_sparse_toy = csr_matrix((np.ones(X_toy.size), \n",
    "                           X_toy.ravel(), \n",
    "                           [X_toy.shape[1] * i for i in range(X_toy.shape[0] + 1)]), dtype=int)[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Размерность разреженной матрицы должна получиться равной 11, поскольку в игрушечном примере 3 пользователя посетили 11 уникальных сайтов.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 3, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       "        [0, 2, 0, 4, 0, 1, 0, 0, 0, 2, 1],\n",
       "        [0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 891,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sparse_toy.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 3, 1, 0, 1, 0, 1, 1, 1, 1, 0],\n",
       "        [3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 0],\n",
       "        [4, 2, 0, 2, 1, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sparse_toy.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_10users, y_10users = train_data_10users.iloc[:, :-1].values, \\\n",
    "                       train_data_10users.iloc[:, -1].values\n",
    "X_150users, y_150users = train_data_150users.iloc[:, :-1].values, \\\n",
    "                         train_data_150users.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse_10users = csr_matrix((np.ones(X_10users.size), \n",
    "                           X_10users.ravel(), \n",
    "                           [X_10users.shape[1] * i for i in range(X_10users.shape[0] + 1)]), dtype=int)[:, 1:]\n",
    "\n",
    "X_sparse_150users = csr_matrix((np.ones(X_150users.size), \n",
    "                           X_150users.ravel(), \n",
    "                           [X_150users.shape[1] * i for i in range(X_150users.shape[0] + 1)]), dtype=int)[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сохраним эти разреженные матрицы с помощью [pickle](https://docs.python.org/2/library/pickle.html) (сериализация в Python), также сохраним вектора *y_10users, y_150users* – целевые значения (id пользователя)  в выборках из 10 и 150 пользователей. То что названия этих матриц начинаются с X и y, намекает на то, что на этих данных мы будем проверять первые модели классификации.\n",
    "Наконец, сохраним также и частотные словари сайтов для 3, 10 и 150 пользователей.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_TO_DATA, 'X_sparse_10users.pkl'), 'wb') as X10_pkl:\n",
    "    pickle.dump(X_sparse_10users, X10_pkl, protocol=2)\n",
    "with open(os.path.join(PATH_TO_DATA, 'y_10users.pkl'), 'wb') as y10_pkl:\n",
    "    pickle.dump(y_10users, y10_pkl, protocol=2)\n",
    "with open(os.path.join(PATH_TO_DATA, 'X_sparse_150users.pkl'), 'wb') as X150_pkl:\n",
    "    pickle.dump(X_sparse_150users, X150_pkl, protocol=2)\n",
    "with open(os.path.join(PATH_TO_DATA, 'y_150users.pkl'), 'wb') as y150_pkl:\n",
    "    pickle.dump(y_150users, y150_pkl, protocol=2)\n",
    "with open(os.path.join(PATH_TO_DATA, 'site_freq_3users.pkl'), 'wb') as site_freq_3users_pkl:\n",
    "    pickle.dump(site_freq_3users, site_freq_3users_pkl, protocol=2)\n",
    "with open(os.path.join(PATH_TO_DATA, 'site_freq_10users.pkl'), 'wb') as site_freq_10users_pkl:\n",
    "    pickle.dump(site_freq_10users, site_freq_10users_pkl, protocol=2)\n",
    "with open(os.path.join(PATH_TO_DATA, 'site_freq_150users.pkl'), 'wb') as site_freq_150users_pkl:\n",
    "    pickle.dump(site_freq_150users, site_freq_150users_pkl, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Чисто для подстраховки проверим, что число столбцов в разреженных матрицах `X_sparse_10users` и `X_sparse_150users` равно ранее посчитанным числам уникальных сайтов для 10 и 150 пользователей соответственно.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert X_sparse_10users.shape[1] == len(site_freq_10users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert X_sparse_150users.shape[1] == len(site_freq_150users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На следующей неделе мы еще немного поготовим данные и потестируем первые гипотезы, связанные с нашими наблюдениями. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
