{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://habrastorage.org/web/677/8e1/337/6778e1337c3d4b159d7e99df94227cb2.jpg\"/>\n",
    "## Специализация \"Машинное обучение и анализ данных\"\n",
    "</center>\n",
    "<center>Автор материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Capstone проект №1. Идентификация пользователей по посещенным веб-страницам\n",
    "<img src='http://i.istockimg.com/file_thumbview_approve/21546327/5/stock-illustration-21546327-identification-de-l-utilisateur.jpg'>\n",
    "\n",
    "# <center>Неделя 6.  Vowpal Wabbit\n",
    "\n",
    "На этой неделе мы познакомимся с популярной библиотекой Vowpal Wabbit и попробуем ее на данных по посещению сайтов.\n",
    "\n",
    "**План 6 недели:**\n",
    "- Часть 1. Статья по Vowpal Wabbit\n",
    "- Часть 2. Применение Vowpal Wabbit к данным по посещению сайтов\n",
    " - 2.1. Подготовка данных\n",
    " - 2.2. Валидация по отложенной выборке\n",
    " - 2.3. Валидация по тестовой выборке (Public Leaderboard)\n",
    "\n",
    "**В этой части проекта Вам могут быть полезны видеозаписи следующих лекций курса \"Обучение на размеченных данных\":**\n",
    "   - [Стохатический градиентный спуск](https://www.coursera.org/learn/supervised-learning/lecture/xRY50/stokhastichieskii-ghradiientnyi-spusk)\n",
    "   - [Линейные модели. Sklearn.linear_model. Классификация](https://www.coursera.org/learn/supervised-learning/lecture/EBg9t/linieinyie-modieli-sklearn-linear-model-klassifikatsiia)\n",
    "   \n",
    "Также будет полезна [презентация](https://github.com/esokolov/ml-course-msu/blob/master/ML15/lecture-notes/Sem08_vw.pdf) лектора специализации Евгения Соколова. И, конечно же, [документация](https://github.com/JohnLangford/vowpal_wabbit/wiki) Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Задание:**</font> заполните код в этой тетрадке и выберите ответы в [веб-форме](https://docs.google.com/forms/d/1wteunpEhAt_9s-WBwxYphB6XpniXsAZiFSNuFNmvOdk). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Статья про Vowpal Wabbit\n",
    "Прочитайте [статью](https://habrahabr.ru/company/ods/blog/326418/) про Vowpal Wabbit на Хабре из серии открытого курса OpenDataScience по машинному обучению. Материал для этой статьи зародился из нашей специализации. Скачайте [тетрадку](https://github.com/Yorko/mlcourse_open/blob/master/jupyter_notebooks/topic08_sgd_hashing_vowpal_wabbit/topic8_sgd_hashing_vowpal_wabbit.ipynb), прилагаемую к статье, посмотрите код, изучите его, поменяйте, только так можно разобраться с Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Применение Vowpal Wabbit к данным по посещению сайтов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Далее посмотрим на Vowpal Wabbit в деле. Правда, в задаче нашего соревнования при бинарной классификации веб-сессий мы разницы не заметим – как по качеству, так и по скорости работы (хотя можете проверить), продемонстрируем всю резвость VW в задаче классификации на 400 классов. Исходные данные все те же самые, но выделено 400 пользователей, и решается задача их идентификации. Скачайте данные [отсюда](https://inclass.kaggle.com/c/identify-me-if-you-can4/data) – файлы `train_sessions_400users.csv` и `test_sessions_400users.csv`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Поменяйте на свой путь к данным\n",
    "# PATH_TO_DATA = '~/capstone_user_identification'\n",
    "PATH_TO_DATA = 'data/capstone_user_identification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузим обучающую и тестовую выборки. Можете заметить, что тестовые сессии здесь по времени четко отделены от сессий в обучающей выборке. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df_400 = pd.read_csv(os.path.join(PATH_TO_DATA,'train_sessions_400users.csv'), \n",
    "                           index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_400 = pd.read_csv(os.path.join(PATH_TO_DATA,'test_sessions_400users.csv'), \n",
    "                           index_col='session_id')\n",
    "#test_df_400.fillna(0, inplace=True).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>site6</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2014-10-04 12:24:43</td>\n",
       "      <td>304.0</td>\n",
       "      <td>2014-10-04 12:25:34</td>\n",
       "      <td>308.0</td>\n",
       "      <td>2014-10-04 12:28:33</td>\n",
       "      <td>307.0</td>\n",
       "      <td>2014-10-04 12:28:33</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2014-10-04 12:28:33</td>\n",
       "      <td>308.0</td>\n",
       "      <td>2014-10-04 12:28:34</td>\n",
       "      <td>312.0</td>\n",
       "      <td>2014-10-04 12:30:31</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2014-10-04 12:31:30</td>\n",
       "      <td>305.0</td>\n",
       "      <td>2014-10-04 12:32:31</td>\n",
       "      <td>309.0</td>\n",
       "      <td>2014-10-04 12:34:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>838</td>\n",
       "      <td>2014-12-02 09:20:37</td>\n",
       "      <td>504.0</td>\n",
       "      <td>2014-12-02 09:20:38</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2014-12-02 09:20:38</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2014-12-02 09:20:38</td>\n",
       "      <td>838.0</td>\n",
       "      <td>2014-12-02 09:20:38</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2014-12-02 09:20:40</td>\n",
       "      <td>838.0</td>\n",
       "      <td>2014-12-02 09:20:41</td>\n",
       "      <td>886.0</td>\n",
       "      <td>2014-12-02 09:20:42</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2014-12-02 09:20:42</td>\n",
       "      <td>305.0</td>\n",
       "      <td>2014-12-02 09:20:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>190</td>\n",
       "      <td>2014-10-01 09:27:38</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2014-10-01 09:27:38</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2014-10-01 09:27:38</td>\n",
       "      <td>189.0</td>\n",
       "      <td>2014-10-01 09:27:38</td>\n",
       "      <td>191.0</td>\n",
       "      <td>2014-10-01 09:27:39</td>\n",
       "      <td>189.0</td>\n",
       "      <td>2014-10-01 09:27:39</td>\n",
       "      <td>190.0</td>\n",
       "      <td>2014-10-01 09:27:39</td>\n",
       "      <td>2375.0</td>\n",
       "      <td>2014-10-01 09:27:39</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2014-10-01 09:27:39</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2014-10-01 09:27:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>295</td>\n",
       "      <td>2014-10-02 14:34:17</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2014-10-02 14:34:18</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2014-10-02 14:34:19</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2014-10-02 14:34:20</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2014-10-02 14:34:21</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2014-10-02 14:34:22</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2014-10-02 14:34:23</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2014-10-02 14:34:24</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2014-10-02 14:34:25</td>\n",
       "      <td>295.0</td>\n",
       "      <td>2014-10-02 14:34:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>2014-05-19 17:50:21</td>\n",
       "      <td>3177.0</td>\n",
       "      <td>2014-05-19 17:50:21</td>\n",
       "      <td>3174.0</td>\n",
       "      <td>2014-05-19 17:50:21</td>\n",
       "      <td>32434.0</td>\n",
       "      <td>2014-05-19 17:50:22</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2014-05-19 17:50:22</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2014-05-19 17:50:22</td>\n",
       "      <td>5698.0</td>\n",
       "      <td>2014-05-19 17:50:25</td>\n",
       "      <td>5698.0</td>\n",
       "      <td>2014-05-19 17:50:26</td>\n",
       "      <td>5698.0</td>\n",
       "      <td>2014-05-19 17:50:27</td>\n",
       "      <td>4173.0</td>\n",
       "      <td>2014-05-19 17:50:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1                time1   site2                time2   site3  \\\n",
       "session_id                                                                    \n",
       "1               9  2014-10-04 12:24:43   304.0  2014-10-04 12:25:34   308.0   \n",
       "2             838  2014-12-02 09:20:37   504.0  2014-12-02 09:20:38    68.0   \n",
       "3             190  2014-10-01 09:27:38   192.0  2014-10-01 09:27:38     8.0   \n",
       "4             295  2014-10-02 14:34:17   295.0  2014-10-02 14:34:18   295.0   \n",
       "5              31  2014-05-19 17:50:21  3177.0  2014-05-19 17:50:21  3174.0   \n",
       "\n",
       "                          time3    site4                time4  site5  \\\n",
       "session_id                                                             \n",
       "1           2014-10-04 12:28:33    307.0  2014-10-04 12:28:33   91.0   \n",
       "2           2014-12-02 09:20:38     11.0  2014-12-02 09:20:38  838.0   \n",
       "3           2014-10-01 09:27:38    189.0  2014-10-01 09:27:38  191.0   \n",
       "4           2014-10-02 14:34:19    295.0  2014-10-02 14:34:20  295.0   \n",
       "5           2014-05-19 17:50:21  32434.0  2014-05-19 17:50:22   27.0   \n",
       "\n",
       "                          time5  site6                time6   site7  \\\n",
       "session_id                                                            \n",
       "1           2014-10-04 12:28:33  308.0  2014-10-04 12:28:34   312.0   \n",
       "2           2014-12-02 09:20:38   11.0  2014-12-02 09:20:40   838.0   \n",
       "3           2014-10-01 09:27:39  189.0  2014-10-01 09:27:39   190.0   \n",
       "4           2014-10-02 14:34:21  295.0  2014-10-02 14:34:22   295.0   \n",
       "5           2014-05-19 17:50:22   31.0  2014-05-19 17:50:22  5698.0   \n",
       "\n",
       "                          time7   site8                time8   site9  \\\n",
       "session_id                                                             \n",
       "1           2014-10-04 12:30:31   300.0  2014-10-04 12:31:30   305.0   \n",
       "2           2014-12-02 09:20:41   886.0  2014-12-02 09:20:42    27.0   \n",
       "3           2014-10-01 09:27:39  2375.0  2014-10-01 09:27:39   192.0   \n",
       "4           2014-10-02 14:34:23   295.0  2014-10-02 14:34:24   295.0   \n",
       "5           2014-05-19 17:50:25  5698.0  2014-05-19 17:50:26  5698.0   \n",
       "\n",
       "                          time9  site10               time10  \n",
       "session_id                                                    \n",
       "1           2014-10-04 12:32:31   309.0  2014-10-04 12:34:31  \n",
       "2           2014-12-02 09:20:42   305.0  2014-12-02 09:20:42  \n",
       "3           2014-10-01 09:27:39     8.0  2014-10-01 09:27:39  \n",
       "4           2014-10-02 14:34:25   295.0  2014-10-02 14:34:26  \n",
       "5           2014-05-19 17:50:27  4173.0  2014-05-19 17:50:27  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_400.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23713</td>\n",
       "      <td>2014-03-24 15:22:40</td>\n",
       "      <td>23720.0</td>\n",
       "      <td>2014-03-24 15:22:48</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:22:48</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:22:54</td>\n",
       "      <td>23720.0</td>\n",
       "      <td>2014-03-24 15:22:54</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-03-24 15:22:55</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:23:01</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:23:03</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:23:04</td>\n",
       "      <td>23713.0</td>\n",
       "      <td>2014-03-24 15:23:05</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8726</td>\n",
       "      <td>2014-04-17 14:25:58</td>\n",
       "      <td>8725.0</td>\n",
       "      <td>2014-04-17 14:25:59</td>\n",
       "      <td>665.0</td>\n",
       "      <td>2014-04-17 14:25:59</td>\n",
       "      <td>8727.0</td>\n",
       "      <td>2014-04-17 14:25:59</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2014-04-17 14:25:59</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-04-17 14:26:01</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2014-04-17 14:26:01</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>2014-04-17 14:26:18</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>2014-04-17 14:26:47</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>2014-04-17 14:26:48</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303</td>\n",
       "      <td>2014-03-21 10:12:24</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2014-03-21 10:12:36</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:12:54</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:13:01</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:13:24</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-03-21 10:13:36</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:13:54</td>\n",
       "      <td>309.0</td>\n",
       "      <td>2014-03-21 10:14:01</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:14:06</td>\n",
       "      <td>303.0</td>\n",
       "      <td>2014-03-21 10:14:24</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1359</td>\n",
       "      <td>2013-12-13 09:52:28</td>\n",
       "      <td>925.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>2013-12-13 09:54:34</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>2013-12-13 09:58:19</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>2013-12-13 09:58:19</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>2013-11-26 12:35:29</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2013-11-26 12:35:31</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2013-11-26 12:35:31</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2013-11-26 12:35:32</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2013-11-26 12:35:32</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-11-26 12:35:32</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2013-11-26 12:37:03</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2013-11-26 12:37:03</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2013-11-26 12:37:03</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2013-11-26 12:37:04</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1                time1    site2                time2    site3  \\\n",
       "session_id                                                                      \n",
       "1           23713  2014-03-24 15:22:40  23720.0  2014-03-24 15:22:48  23713.0   \n",
       "2            8726  2014-04-17 14:25:58   8725.0  2014-04-17 14:25:59    665.0   \n",
       "3             303  2014-03-21 10:12:24     19.0  2014-03-21 10:12:36    303.0   \n",
       "4            1359  2013-12-13 09:52:28    925.0  2013-12-13 09:54:34   1240.0   \n",
       "5              11  2013-11-26 12:35:29     85.0  2013-11-26 12:35:31     52.0   \n",
       "\n",
       "                          time3    site4                time4    site5  \\\n",
       "session_id                                                               \n",
       "1           2014-03-24 15:22:48  23713.0  2014-03-24 15:22:54  23720.0   \n",
       "2           2014-04-17 14:25:59   8727.0  2014-04-17 14:25:59     45.0   \n",
       "3           2014-03-21 10:12:54    303.0  2014-03-21 10:13:01    303.0   \n",
       "4           2013-12-13 09:54:34   1360.0  2013-12-13 09:54:34   1344.0   \n",
       "5           2013-11-26 12:35:31     85.0  2013-11-26 12:35:32     11.0   \n",
       "\n",
       "                          time5   ...                  time6    site7  \\\n",
       "session_id                        ...                                   \n",
       "1           2014-03-24 15:22:54   ...    2014-03-24 15:22:55  23713.0   \n",
       "2           2014-04-17 14:25:59   ...    2014-04-17 14:26:01     45.0   \n",
       "3           2014-03-21 10:13:24   ...    2014-03-21 10:13:36    303.0   \n",
       "4           2013-12-13 09:54:34   ...    2013-12-13 09:54:34   1346.0   \n",
       "5           2013-11-26 12:35:32   ...    2013-11-26 12:35:32     11.0   \n",
       "\n",
       "                          time7    site8                time8    site9  \\\n",
       "session_id                                                               \n",
       "1           2014-03-24 15:23:01  23713.0  2014-03-24 15:23:03  23713.0   \n",
       "2           2014-04-17 14:26:01   5320.0  2014-04-17 14:26:18   5320.0   \n",
       "3           2014-03-21 10:13:54    309.0  2014-03-21 10:14:01    303.0   \n",
       "4           2013-12-13 09:54:34   1345.0  2013-12-13 09:54:34   1344.0   \n",
       "5           2013-11-26 12:37:03     85.0  2013-11-26 12:37:03     10.0   \n",
       "\n",
       "                          time9   site10               time10 user_id  \n",
       "session_id                                                             \n",
       "1           2014-03-24 15:23:04  23713.0  2014-03-24 15:23:05     653  \n",
       "2           2014-04-17 14:26:47   5320.0  2014-04-17 14:26:48     198  \n",
       "3           2014-03-21 10:14:06    303.0  2014-03-21 10:14:24      34  \n",
       "4           2013-12-13 09:58:19   1345.0  2013-12-13 09:58:19     601  \n",
       "5           2013-11-26 12:37:03     85.0  2013-11-26 12:37:04     273  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_400.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Видим, что в обучающей выборке 182793 сессий, в тестовой – 46473, и сессии действительно принадлежат 400 различным пользователям.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((182793, 21), (46473, 20), 400)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_400.shape, test_df_400.shape, train_df_400['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vowpal Wabbit любит, чтоб метки классов были распределены от 1 до K, где K – число классов в задаче классификации (в нашем случае – 400). Поэтому придется применить `LabelEncoder`, да еще и +1 потом добавить (`LabelEncoder` переводит метки в диапозон от 0 до K-1). Потом надо будет применить обратное преобразование.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "y = train_df_400['user_id'].values\n",
    "class_encoder = preprocessing.LabelEncoder()\n",
    "y_for_vw = class_encoder.fit_transform(y) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([262,  82,  16, ..., 254,  91, 256], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Далее будем сравнивать VW с SGDClassifier и с логистической регрессией. Всем моделям этим нужна предобработка входных данных. Подготовьте для sklearn-моделей разреженные матрицы, как мы это делали в 5 части:**\n",
    "- объедините обучающиую и тестовую выборки\n",
    "- выберите только сайты (признаки от 'site1' до 'site10')\n",
    "- замените пропуски на нули (сайты у нас нумеровались с 0)\n",
    "- переведите в разреженный формат `csr_matrix`\n",
    "- разбейте обратно на обучающую и тестовую части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites = ['site' + str(i) for i in range(1, 11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "train_test_df_400 = pd.concat([train_df_400, test_df_400])\n",
    "train_test_df_sites_400 = train_test_df_400[sites].fillna(0).astype('int')\n",
    "\n",
    "train_test_sparse_400 = csr_matrix((np.ones(train_test_df_sites_400.values.size), \n",
    "                               train_test_df_sites_400.values.ravel(), \n",
    "                               [train_test_df_sites_400.values.shape[1] * i \n",
    "                                for i in range(train_test_df_sites_400.values.shape[0] + 1)]), dtype=int)[:, 1:]\n",
    "X_train_sparse = train_test_sparse_400[:train_df_400.shape[0]]\n",
    "X_test_sparse = train_test_sparse_400[train_df_400.shape[0]:]\n",
    "y = train_df_400['user_id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Валидация по отложенной выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выделим обучающую (70%) и отложенную (30%) части исходной обучающей выборки. Данные не перемешиваем, учитываем, что сессии отсортированы по времени.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_share = int(.7 * train_df_400.shape[0])\n",
    "train_df_part = train_df_400[sites].fillna(0).astype('int').iloc[:train_share, :]\n",
    "valid_df = train_df_400[sites].fillna(0).astype('int').iloc[train_share:, :]\n",
    "X_train_part_sparse = X_train_sparse[:train_share, :]\n",
    "X_valid_sparse = X_train_sparse[train_share:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_part = y[:train_share]\n",
    "y_valid = y[train_share:]\n",
    "y_train_part_for_vw = y_for_vw[:train_share]\n",
    "y_valid_for_vw = y_for_vw[train_share:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Реализуйте функцию, `arrays_to_vw`, переводящую обучающую выборку в формат Vowpal Wabbit.**\n",
    "\n",
    "Вход:\n",
    " - X – матрица `NumPy` (обучающая выборка)\n",
    " - y (необяз.) - вектор ответов (`NumPy`). Необязателен, поскольку тестовую матрицу будем обрабатывать этой же функцией\n",
    " - train – флаг, True в случае обучающей выборки, False – в случае тестовой выборки\n",
    " - out_file – путь к файлу .vw, в который будет произведена запись\n",
    " \n",
    "Детали:\n",
    "- надо пройтись по всем строкам матрицы `X` и записать через пробел все значения, предварительно добавив вперед нужную метку класса из вектора `y` и знак-разделитель `|`\n",
    "- в тестовой выборке на месте меток целевого класса можно писать произвольные, допустим, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrays_to_vw(X, y=None, train=True, out_file='tmp.vw'):\n",
    "    ''' ВАШ КОД ЗДЕСЬ '''\n",
    "    with open(out_file, 'w') as out_vw:\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            if train:\n",
    "                target = y[i]\n",
    "            else:\n",
    "                target = 1\n",
    "\n",
    "            s = '{} | {} {} {} {} {} {} {} {} {} {}\\n'.format(\n",
    "                 target, X[i, 0], X[i, 1], X[i, 2], X[i, 3], X[i, 4], X[i, 5], X[i, 6], X[i, 7], X[i, 8], X[i, 9])\n",
    "            out_vw.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примените написанную функцию к части обучащей выборки `(train_df_part, y_train_part_for_vw)`, к отложенной выборке `(valid_df, y_valid_for_vw)`, ко всей обучающей выборке и ко всей тестовой выборке. Обратите внимание, что на вход наш метод принимает именно матрицы и вектора `NumPy`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127955, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_part.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# будет 4 вызова\n",
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "arrays_to_vw(train_df_part.values, y_train_part_for_vw, train=True, out_file=os.path.join(PATH_TO_DATA, 'train_part.vw'))\n",
    "arrays_to_vw(valid_df.values, y_valid_for_vw, train=True, out_file=os.path.join(PATH_TO_DATA, 'valid.vw'))\n",
    "arrays_to_vw(train_df_400[sites].values, y_for_vw, train=True, out_file=os.path.join(PATH_TO_DATA, 'train.vw'))\n",
    "arrays_to_vw(test_df_400[sites].values, train=False, out_file=os.path.join(PATH_TO_DATA, 'test.vw'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат должен получиться таким.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 | 23713 23720 23713 23713 23720 23713 23713 23713 23713 23713\n",
      "82 | 8726 8725 665 8727 45 8725 45 5320 5320 5320\n",
      "16 | 303 19 303 303 303 303 303 309 303 303\n"
     ]
    }
   ],
   "source": [
    "!head -3 $PATH_TO_DATA/train_part.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262 | 23713 23720 23713 23713 23720 23713 23713 23713 23713 23713\r\n",
      "82 | 8726 8725 665 8727 45 8725 45 5320 5320 5320\r\n",
      "16 | 303 19 303 303 303 303 303 309 303 303\r\n"
     ]
    }
   ],
   "source": [
    "!head -3 $PATH_TO_DATA/train_part.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 | 7 923 923 923 11 924 7 924 838 7\n",
      "160 | 91 198 11 11 302 91 668 311 310 91\n",
      "312 | 27085 848 118 118 118 118 11 118 118 118\n"
     ]
    }
   ],
   "source": [
    "!head -3  $PATH_TO_DATA/valid.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 | 7 923 923 923 11 924 7 924 838 7\r\n",
      "160 | 91 198 11 11 302 91 668 311 310 91\r\n",
      "312 | 27085 848 118 118 118 118 11 118 118 118\r\n"
     ]
    }
   ],
   "source": [
    "!head -3  $PATH_TO_DATA/valid.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 | 9.0 304.0 308.0 307.0 91.0 308.0 312.0 300.0 305.0 309.0\n",
      "1 | 838.0 504.0 68.0 11.0 838.0 11.0 838.0 886.0 27.0 305.0\n",
      "1 | 190.0 192.0 8.0 189.0 191.0 189.0 190.0 2375.0 192.0 8.0\n"
     ]
    }
   ],
   "source": [
    "!head -3 $PATH_TO_DATA/test.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 | 9 304 308 307 91 308 312 300 305 309\r\n",
      "1 | 838 504 68 11 838 11 838 886 27 305\r\n",
      "1 | 190 192 8 189 191 189 190 2375 192 8\r\n"
     ]
    }
   ],
   "source": [
    "!head -3 $PATH_TO_DATA/test.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите модель Vowpal Wabbitна выборке `train_part.vw`. Укажите, что решается задача классификации с 400 классами (`--oaa`), сделайте 3 прохода по выборке (`--passes`). Задайте некоторый кэш-файл (`--cache_file`, можно просто указать флаг `-c`), так VW будет быстрее делать все следующие после первого проходы по выборке (прошлый кэш-файл удаляется с помощью аргумента `-k`). Также укажите значение параметра `b`=26. Это число бит, используемых для хэширования, в данном случае нужно больше, чем 18 по умолчанию. Наконец, укажите `random_seed`=17. Остальные параметры пока не меняйте, далее уже в свободном режиме соревнования можете попробовать другие функции потерь.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_part_vw = os.path.join(PATH_TO_DATA, 'train_part.vw')\n",
    "valid_vw = os.path.join(PATH_TO_DATA, 'valid.vw')\n",
    "train_vw = os.path.join(PATH_TO_DATA, 'train.vw')\n",
    "test_vw = os.path.join(PATH_TO_DATA, 'test.vw')\n",
    "model = os.path.join(PATH_TO_DATA, 'vw_model.vw')\n",
    "pred = os.path.join(PATH_TO_DATA, 'vw_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "final_regressor = data/capstone_user_identification\\vw_model.vw\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = data/capstone_user_identification\\train_part.vw.cache\n",
      "Reading datafile = data/capstone_user_identification\\train_part.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0      262        1       11\n",
      "1.000000 1.000000            2            2.0       82      262       11\n",
      "1.000000 1.000000            4            4.0      241      262       11\n",
      "1.000000 1.000000            8            8.0      352      262       11\n",
      "1.000000 1.000000           16           16.0      135       16       11\n",
      "1.000000 1.000000           32           32.0       71      112       11\n",
      "0.968750 0.937500           64           64.0      358      231       11\n",
      "0.976563 0.984375          128          128.0      348      346       11\n",
      "0.941406 0.906250          256          256.0      202      202       11\n",
      "0.947266 0.953125          512          512.0       30        1       11\n",
      "0.925781 0.904297         1024         1024.0       36      290       11\n",
      "0.908203 0.890625         2048         2048.0       21      128       11\n",
      "0.880127 0.852051         4096         4096.0       80      229       11\n",
      "0.856323 0.832520         8192         8192.0      307      356       11\n",
      "0.828003 0.799683        16384        16384.0       59      193       11\n",
      "0.795441 0.762878        32768        32768.0      262       30       11\n",
      "0.760468 0.725494        65536        65536.0      171      238       11\n",
      "0.724008 0.724008       131072       131072.0        6        6       11 h\n",
      "0.697339 0.670672       262144       262144.0       12       12       11 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 115160\n",
      "passes used = 3\n",
      "weighted example sum = 345480.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.661352 h\n",
      "total feature number = 3800280\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "# обучаем\n",
    "\n",
    "!vw \\\n",
    "-d $train_part_vw \\\n",
    "-f $model \\\n",
    "--oaa 400 \\\n",
    "-c \\\n",
    "--passes 3 \\\n",
    "-k \\\n",
    "-b 26 \\\n",
    "--random_seed=17 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запишите прогнозы на выборке *valid.vw* в *vw_valid_pred.csv*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.26 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = data/capstone_user_identification/vw_valid_pred.csv\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = data/capstone_user_identification\\valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        4      188       11\n",
      "1.000000 1.000000            2            2.0      160      220       11\n",
      "0.750000 0.500000            4            4.0      143      143       11\n",
      "0.750000 0.750000            8            8.0      247      247       11\n",
      "0.687500 0.625000           16           16.0      341       30       11\n",
      "0.593750 0.500000           32           32.0      237      237       11\n",
      "0.609375 0.625000           64           64.0      178      178       11\n",
      "0.640625 0.671875          128          128.0      132      228       11\n",
      "0.656250 0.671875          256          256.0       14       14       11\n",
      "0.646484 0.636719          512          512.0      370      370       11\n",
      "0.663086 0.679688         1024         1024.0      189      189       11\n",
      "0.655762 0.648438         2048         2048.0      311      311       11\n",
      "0.657227 0.658691         4096         4096.0      195      318       11\n",
      "0.660156 0.663086         8192         8192.0      171      195       11\n",
      "0.657654 0.655151        16384        16384.0      362       51       11\n",
      "0.655121 0.652588        32768        32768.0      248      248       11\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 54838\n",
      "passes used = 1\n",
      "weighted example sum = 54838.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.654583\n",
      "total feature number = 603218\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "# прогноз на выборке valid.vw* в *vw_valid_pred.csv\n",
    "\n",
    "!vw \\\n",
    "-i $model -t \\\n",
    "-d $valid_vw \\\n",
    "-p $PATH_TO_DATA/vw_valid_pred.csv \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Считайте прогнозы *kaggle_data/vw_valid_pred.csv*  из файла и посмотрите на долю правильных ответов на отложенной части.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "vw_valid_pred_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'vw_valid_pred.csv'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  188\n",
       "1  220\n",
       "2  364\n",
       "3  143\n",
       "4  132"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vw_valid_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34541741128414605"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(vw_valid_pred_df, y_valid_for_vw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь обучите `SGDClassifier` (3 прохода по выборке, логистическая функция потерь) и `LogisticRegression` на 70% разреженной обучающей выборки – `(X_train_part_sparse, y_train_part)`, сделайте прогноз для отложенной выборки `(X_valid_sparse, y_valid)` и посчитайте доли верных ответов. Логистическая регрессия будет обучаться долго (у меня – 15 минут) – это нормально. Укажите везде `random_state`=17, `n_jobs`=-1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "logit = LogisticRegression(random_state=17, n_jobs=-1)\n",
    "sgd_logit = SGDClassifier(loss='log', n_iter=3, random_state=17, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "logit.fit(X_train_part_sparse, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "sgd_logit.fit(X_train_part_sparse, y_train_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'>Вопрос 1. </font> Посчитайте долю правильных ответов на отложенной выборке для Vowpal Wabbit, округлите до 3 знаков после запятой.**\n",
    "\n",
    "**<font color='red'>Вопрос 2. </font> Посчитайте долю правильных ответов на отложенной выборке для SGD, округлите до 3 знаков после запятой.**\n",
    "\n",
    "**<font color='red'>Вопрос 3. </font> Посчитайте долю правильных ответов на отложенной выборке для логистической регрессии, округлите до 3 знаков после запятой.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vw_valid_acc = 0.345, \n",
      "sgd_valid_acc = 0.291, \n",
      "logit_valid_acc = 0.363\n"
     ]
    }
   ],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "vw_valid_acc = accuracy_score(vw_valid_pred_df, y_valid_for_vw)\n",
    "logit_valid_acc = accuracy_score(logit.predict(X_valid_sparse), y_valid)\n",
    "sgd_valid_acc = accuracy_score(sgd_logit.predict(X_valid_sparse), y_valid)\n",
    "print(\"vw_valid_acc = {}, \\nsgd_valid_acc = {}, \\nlogit_valid_acc = {}\".format(round(vw_valid_acc, 3), round(sgd_valid_acc, 3),\n",
    "                                     round(logit_valid_acc, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, file_address):\n",
    "    with open(file_address, 'w') as out_f:\n",
    "        out_f.write(str(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_answer_to_file(\"{}  {} {}\".format(round(vw_valid_acc, 3), round(sgd_valid_acc, 3),\n",
    "                                     round(logit_valid_acc, 3)),  \n",
    "                     'answer6_1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Валидация по тестовой выборке (Public Leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите модель VW с теми же параметрами на всей обучающей выборке – *train.vw*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "final_regressor = data/capstone_user_identification/vw_model_train.vw\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = data/capstone_user_identification\\train.vw.cache\n",
      "Reading datafile = data/capstone_user_identification\\train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0      262        1       11\n",
      "1.000000 1.000000            2            2.0       82      262       11\n",
      "1.000000 1.000000            4            4.0      241      262       11\n",
      "1.000000 1.000000            8            8.0      352      262       11\n",
      "1.000000 1.000000           16           16.0      135       16       11\n",
      "1.000000 1.000000           32           32.0       71      112       11\n",
      "0.968750 0.937500           64           64.0      358      231       11\n",
      "0.976563 0.984375          128          128.0      348      346       11\n",
      "0.941406 0.906250          256          256.0      202      202       11\n",
      "0.947266 0.953125          512          512.0       30        1       11\n",
      "0.925781 0.904297         1024         1024.0       36      290       11\n",
      "0.907715 0.889648         2048         2048.0       21      128       11\n",
      "0.879883 0.852051         4096         4096.0       80      229       11\n",
      "0.856323 0.832764         8192         8192.0      307      356       11\n",
      "0.828064 0.799805        16384        16384.0       59      193       11\n",
      "0.795898 0.763733        32768        32768.0      262       30       11\n",
      "0.761475 0.727051        65536        65536.0      171      238       11\n",
      "0.726791 0.692108       131072       131072.0      180      159       11\n",
      "0.694671 0.694671       262144       262144.0       88      221       11 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 164514\n",
      "passes used = 3\n",
      "weighted example sum = 493542.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.645057 h\n",
      "total feature number = 5428962\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw \\\n",
    "-d $train_vw \\\n",
    "-f $PATH_TO_DATA/vw_model_train.vw \\\n",
    "--oaa 400 \\\n",
    "-c \\\n",
    "--passes 3 \\\n",
    "-k \\\n",
    "-b 26 \\\n",
    "--random_seed=17 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделайте прогноз для тестовой выборки.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.63 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = data/capstone_user_identification/vw_train_pred.csv\n",
      "Num weight bits = 26\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = data/capstone_user_identification\\train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0      262      262       11\n",
      "0.000000 0.000000            2            2.0       82       82       11\n",
      "0.500000 1.000000            4            4.0      241      212       11\n",
      "0.625000 0.750000            8            8.0      352      352       11\n",
      "0.750000 0.875000           16           16.0      156      354       11\n",
      "0.656250 0.562500           32           32.0      243      243       11\n",
      "0.562500 0.468750           64           64.0       79       79       11\n",
      "0.570313 0.578125          128          128.0      298      194       11\n",
      "0.550781 0.531250          256          256.0      383      227       11\n",
      "0.560547 0.570313          512          512.0      298      298       11\n",
      "0.568359 0.576172         1024         1024.0        7       90       11\n",
      "0.561035 0.553711         2048         2048.0      134      134       11\n",
      "0.557129 0.553223         4096         4096.0      255      287       11\n",
      "0.557373 0.557617         8192         8192.0      354       48       11\n",
      "0.552612 0.547852        16384        16384.0      238      193       11\n",
      "0.554291 0.555969        32768        32768.0      213       37       11\n",
      "0.553925 0.553558        65536        65536.0      281      281       11\n",
      "0.548805 0.543686       131072       131072.0       59       59       11\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 182793\n",
      "passes used = 1\n",
      "weighted example sum = 182793.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.536158\n",
      "total feature number = 2010723\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw \\\n",
    "-i $PATH_TO_DATA/vw_model_train.vw -t \\\n",
    "-d $train_vw \\\n",
    "-p $PATH_TO_DATA/vw_train_pred.csv \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запишите прогноз в файл, примените обратное преобразование меток (был LabelEncoder и потом +1 в меткам) и отправьте решение на Kaggle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='user_id', index_label=\"session_id\"):\n",
    "    # turn predictions into data frame and save as csv file\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "vw_pred = class_encoder.inverse_transform(pd.read_csv(os.path.join(PATH_TO_DATA, 'vw_train_pred.csv'), header=None).values - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(vw_pred, os.path.join(PATH_TO_DATA, 'vw_400_users.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vw_400_users = pd.read_csv(os.path.join(PATH_TO_DATA, 'vw_400_users.csv'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>session_id</td>\n",
       "      <td>user_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1\n",
       "0  session_id  user_id\n",
       "1           1      653\n",
       "2           2      198\n",
       "3           3      635\n",
       "4           4      541"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vw_400_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182794, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vw_400_users.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделайте то же самое для SGD и логистической регрессии. Тут уже ждать обучение логистической регрессии совсем скучно (заново запускать тетрадку вам не захочется), но давайте дождемся.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''\n",
    "logit_test_pred = logit.fit(X_train_sparse, y).predict(X_test_sparse)\n",
    "sgd_logit_test_pred = sgd_logit.fit(X_train_sparse, y).predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_submission_file(logit_test_pred, \n",
    "                         os.path.join(PATH_TO_DATA, 'logit_400_users.csv'))\n",
    "write_to_submission_file(sgd_logit_test_pred, \n",
    "                         os.path.join(PATH_TO_DATA, 'sgd_400_users.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit_400_users = pd.read_csv(os.path.join(PATH_TO_DATA, 'logit_400_users.csv'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46469</th>\n",
       "      <td>46469</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46470</th>\n",
       "      <td>46470</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46471</th>\n",
       "      <td>46471</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46472</th>\n",
       "      <td>46472</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46473</th>\n",
       "      <td>46473</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1\n",
       "46469  46469  213\n",
       "46470  46470    7\n",
       "46471  46471  656\n",
       "46472  46472  751\n",
       "46473  46473  179"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_400_users[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на доли правильных ответов на публичной части (public leaderboard) тестовой выборки [этого](https://inclass.kaggle.com/c/identify-me-if-you-can4) соревнования.\n",
    "\n",
    "**<font color='red'>Вопрос 4. </font> Какова доля правильных ответов на публичной части тестовой выборки (public leaderboard)  для Vowpal Wabbit?**\n",
    "\n",
    "**<font color='red'>Вопрос 5. </font> Какова доля правильных ответов на публичной части тестовой выборки (public leaderboard)  для SGD?**\n",
    "\n",
    "**<font color='red'>Вопрос 6. </font> Какова доля правильных ответов на публичной части тестовой выборки (public leaderboard)  для логистической регрессии?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В заключение по заданию:**\n",
    "- Про соотношение качества классификации и скорости обучения VW, SGD и logit выводы предлагается сделать самостоятельно\n",
    "- Пожалуй, задача классификации на 400 классов (идентификация 400 пользователей) решается недостаточно хорошо при честном отделении по времени тестовой выборки от обучающей. Далее мы будем соревноваться в идентификации одного пользователя (Элис) – [вот](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2) соревнование, в котором предлагается поучаствовать. Не перепутайте! \n",
    "\n",
    "**Удачи!**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
